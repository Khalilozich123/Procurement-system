version: '3'

services:
  # --- 1. STORAGE LAYER (HDFS) ---
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - "9870:9870" # Web UI
      - "9000:9000" # IPC
    env_file:       
      - ./hadoop.env
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    volumes:
      - namenode_data:/hadoop/dfs/name

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    environment:
      - SERVICE_PRECONDITION=namenode:9000
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    env_file:       
      - ./hadoop.env
    volumes:
      - datanode_data:/hadoop/dfs/data

  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode2
    restart: always
    volumes:
      - ./hadoop_data/datanode2:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9000"
    env_file:
      - ./hadoop.env

  datanode3:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode3
    restart: always
    volumes:
      - ./hadoop_data/datanode3:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9000"
    env_file:
      - ./hadoop.env

  # --- 2. OPERATIONAL LAYER (PostgreSQL) ---
  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: procurement_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data


# --- 3. METADATA LAYER (Self-Healing) ---
  hive-metastore:
    image: apache/hive:3.1.3
    container_name: hive-metastore
    user: "root"
    ports:
      - "9083:9083"
    environment:
      - SERVICE_NAME=metastore
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:derby:/metastore_storage/metastore_db;create=true
    volumes:
      - hive_data:/user/hive/warehouse
      - metastore_db_data:/metastore_storage
    entrypoint: /bin/sh
    command: >
      -c "
        export HIVE_CONF_DIR=/opt/hive/conf;
        if [ ! -f /metastore_storage/.schema_initialized ]; then
          echo 'Initializing schema for the first time...';
          /opt/hive/bin/schematool -dbType derby -initSchema -verbose &&
          touch /metastore_storage/.schema_initialized;
        else
          echo 'Schema already initialized, skipping...';
        fi;
        echo 'Removing stale Derby lock files...';
        rm -f /metastore_storage/metastore_db/*.lck /metastore_storage/metastore_db/db.lck /metastore_storage/metastore_db/dbex.lck;
        echo 'Starting Hive Metastore...';
        /opt/hive/bin/hive --service metastore
      "

  # --- 4. COMPUTE LAYER (Trino/Presto) ---
  trino:
    image: trinodb/trino:latest
    container_name: trino
    environment:
      - HADOOP_CONF_DIR=/etc/hadoop/conf
    ports:
      - "8080:8080"
    volumes:
      # Mount the whole config directory (Simplest method)
      - ./trino-etc:/etc/trino
      # Mount the Hadoop config directory so Trino can find core-site.xml
      - ./hadoop-conf:/etc/hadoop/conf
    depends_on:
      - namenode
      - postgres
      - hive-metastore
  
  # --- 5. ORCHESTRATION LAYER (The Scheduler) ---
  scheduler:
    build:
      context: .
      dockerfile: Dockerfile.scheduler
    container_name: scheduler
    depends_on:
      - postgres
      - trino
      - namenode
    volumes:
      - ./scripts:/app/scripts
      - ./generated_data:/app/generated_data 
      - /var/run/docker.sock:/var/run/docker.sock 

volumes:
  namenode_data:
  datanode_data:
  postgres_data:
  hive_data:
  metastore_db_data: